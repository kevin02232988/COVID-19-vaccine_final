import pandas as pd
import matplotlib.pyplot as plt
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
import nltk

# -------------------------------------------------------------------------------------
# 0. í™˜ê²½ ì„¤ì •
# -------------------------------------------------------------------------------------
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

ABSOLUTE_PATH = r"C:\Users\user\PycharmProjects\PythonProject6\\"
FILE_SENTIMENT = ABSOLUTE_PATH + "DDDD.csv"

nltk.download('stopwords')
stop_words = stopwords.words('english')

# -------------------------------------------------------------------------------------
# 1. ë°ì´í„° ë¡œë“œ
# -------------------------------------------------------------------------------------
df = pd.read_csv(FILE_SENTIMENT)
df = df.dropna(subset=['text'])

print("ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", df.shape)

# -------------------------------------------------------------------------------------
# 2. ê¸ì • / ë¶€ì • ë¶„ë¦¬
# -------------------------------------------------------------------------------------
df_pos = df[df['sentiment_label'] == 1].copy()
df_neg = df[df['sentiment_label'] == 0].copy()

print(f"ê¸ì • ë¦¬ë·° ìˆ˜: {len(df_pos)}, ë¶€ì • ë¦¬ë·° ìˆ˜: {len(df_neg)}")

# -------------------------------------------------------------------------------------
# 3. ê³µí†µ Vectorizer
# -------------------------------------------------------------------------------------
vectorizer_model = CountVectorizer(stop_words=stop_words)

# -------------------------------------------------------------------------------------
# 4. ë¶€ì • ë¦¬ë·° í† í”½ ëª¨ë¸ë§
# -------------------------------------------------------------------------------------
print("\nğŸ”µ ë¶€ì • ë¦¬ë·° í† í”½ ëª¨ë¸ë§ ì‹œì‘...")
topic_model_neg = BERTopic(
    vectorizer_model=vectorizer_model,
    language="multilingual",
    calculate_probabilities=True
)

topics_neg, probs_neg = topic_model_neg.fit_transform(df_neg["text"])
df_neg["topic"] = topics_neg
topic_model_neg.save("bertopic_negative")

print("ë¶€ì • ì£¼ìš” í† í”½ ì˜ˆì‹œ:")
print(topic_model_neg.get_topic(0))

# -------------------------------------------------------------------------------------
# 5. ê¸ì • ë¦¬ë·° í† í”½ ëª¨ë¸ë§
# -------------------------------------------------------------------------------------
print("\nğŸŸ¢ ê¸ì • ë¦¬ë·° í† í”½ ëª¨ë¸ë§ ì‹œì‘...")
topic_model_pos = BERTopic(
    vectorizer_model=vectorizer_model,
    language="multilingual",
    calculate_probabilities=True
)

topics_pos, probs_pos = topic_model_pos.fit_transform(df_pos["text"])
df_pos["topic"] = topics_pos
topic_model_pos.save("bertopic_positive")

print("ê¸ì • ì£¼ìš” í† í”½ ì˜ˆì‹œ:")
print(topic_model_pos.get_topic(0))

# -------------------------------------------------------------------------------------
# 6. ê¸/ë¶€ì • ë¹„ìœ¨ ê·¸ë˜í”„ (ì •ì  ë§‰ëŒ€ ì°¨íŠ¸)
# -------------------------------------------------------------------------------------
pos_count = len(df_pos)
neg_count = len(df_neg)
total = pos_count + neg_count

plt.figure(figsize=(6, 5))
plt.bar(['Positive', 'Negative'], [pos_count / total, neg_count / total])
plt.title("ê¸ì • / ë¶€ì • ë¹„ìœ¨")
plt.ylabel("ë¹„ìœ¨")
plt.tight_layout()
plt.savefig("sentiment_ratio.png")
plt.show()

print("\nğŸ“Š ê¸ë¶€ì • ë¹„ìœ¨ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ â†’ sentiment_ratio.png")

# -------------------------------------------------------------------------------------
# 7. í† í”½ ê²°ê³¼ ì €ì¥
# -------------------------------------------------------------------------------------
df_neg.to_csv("negative_topics_2.csv", index=False, encoding='utf-8-sig')
df_pos.to_csv("positive_topics_2.csv", index=False, encoding='utf-8-sig')

print("ğŸ“ í† í”½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: negative_topics.csv / positive_topics.csv")
