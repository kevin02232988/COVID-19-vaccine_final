import pandas as pd
from collections import Counter
import re

# íŒŒì¼ ë¡œë“œ
OUTPUT_PREDICTED_FILE = "FINAL_ANALYSIS_DATA_with_Sentiment.csv"
try:
    df_final = pd.read_csv(OUTPUT_PREDICTED_FILE)
except FileNotFoundError:
    print(f"[ERROR] ìµœì¢… ì˜ˆì¸¡ íŒŒì¼ ('{OUTPUT_PREDICTED_FILE}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    exit()

# 1. ë¶€ì •ì ì¸ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§ (74,954ê±´)
df_negative = df_final[df_final['Predicted_Sentiment'] == 'Negative'].copy()
negative_texts = df_negative['text'].astype(str).str.lower()

# 2. ë¶„ì„í•  í† í”½ í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜ (NMF ê²°ê³¼ ê¸°ë°˜)
# í† í”½ 1, 2, 4, 5ì˜ í•µì‹¬ í‚¤ì›Œë“œ ë° ë…¼ë€ í‚¤ì›Œë“œ
CORE_TOPIC_KEYWORDS = [
    'mask', 'masks', 'wear', 'wearing', 'right', 'work', 'virus', 'feel', 'long', 'side effect',
    'adverse', 'money', 'shit', 'youtube', 'com', 'reddit', 'message'
]

# 3. ë¶ˆìš©ì–´ ëª©ë¡ (ì´ì „ ë‹¨ê³„ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
STOP_WORDS_LIST = [
    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',
    'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',
    'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',
    'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
    'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',
    'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about',
    'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below',
    'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',
    'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each',
    'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',
    'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now',
    'covid', 'vaccine', 'get', 'would', 'could', 'one', 'take', 'need', 'people', 'us', 'say',
    'make', 'go', 'know', 'see', 'many', 'like', 'think', 'dont', 'im', 'ive', 'said', 'thats',
    'really', 'back', 'much', 'still', 'even', 'want', 'time', 'also', 'something', 'going',
    'look', 'lot', 'way', 'got', 'didnt', 'anyone', 'new', 'ever', 'may', 'tell', 'last',
    'week', 'every', 'things', 'using', 'way', 'since', 'first', 'getting', 'without'
]


# 4. ì–¸ê¸‰ íšŸìˆ˜ ê³„ì‚° (ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê° í‚¤ì›Œë“œì˜ ë“±ì¥ íšŸìˆ˜)
keyword_counts = Counter()
total_texts = len(df_negative)

for keyword in CORE_TOPIC_KEYWORDS:
    # í…ìŠ¤íŠ¸ ë‚´ì—ì„œ í‚¤ì›Œë“œì˜ ë“±ì¥ íšŸìˆ˜ë¥¼ ì§ì ‘ ì¹´ìš´íŠ¸
    count = df_negative['text'].str.lower().str.count(r'\b' + re.escape(keyword) + r'\b').sum()
    keyword_counts[keyword] = count

# 5. ê²°ê³¼ DataFrame ìƒì„± ë° ì¶œë ¥ (ë…¼ì˜ ê·œëª¨ ì‹œê°í™”)
df_counts = pd.DataFrame(keyword_counts.items(), columns=['Keyword', 'Total Mentions'])
df_counts['Mentions per 1000 texts'] = (df_counts['Total Mentions'] / total_texts) * 1000

# ì–¸ê¸‰ íšŸìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
df_counts = df_counts.sort_values(by='Total Mentions', ascending=False)

print("\n## ğŸ“Š í•µì‹¬ ë…¼ë€ í‚¤ì›Œë“œ ì´ ì–¸ê¸‰ ë¹ˆë„")
print("---")
print(f"**ë¶„ì„ ëŒ€ìƒ ë°ì´í„°:** {total_texts}ê±´ (Negative Sentiment)")
print("\n--- ë…¼ë€ í‚¤ì›Œë“œ ì´ ì–¸ê¸‰ íšŸìˆ˜ ---")
print(df_counts.to_markdown(index=False))

print("\n")

# 6. ë³´ê³ ì„œìš© ì´ë¯¸ì§€ ì‹œê°í™” (ë§‰ëŒ€ ê·¸ë˜í”„)
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
# íšŸìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í”Œë¡œíŒ…
sns.barplot(x='Total Mentions', y='Keyword', data=df_counts, color='#E34A33')

plt.title('í•µì‹¬ ë…¼ë€ í‚¤ì›Œë“œ ì´ ì–¸ê¸‰ íšŸìˆ˜ (Negative Sentiment)', fontsize=14)
plt.xlabel('ì´ ì–¸ê¸‰ íšŸìˆ˜', fontsize=12)
plt.ylabel('í‚¤ì›Œë“œ', fontsize=12)
plt.tight_layout()

plt.savefig("controversy_keyword_mentions.png")
plt.close()